{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_bots_tweets = pd.read_csv('social_honeypot_icwsm_2011/content_polluters_tweets.txt', \n",
    "                            sep='\\t', \n",
    "                            header=None,\n",
    "                            names=[\"UserID\", \"TweetID\", \"Tweet\", \"CreatedAt\"])\n",
    "\n",
    "df_humans_tweets = pd.read_csv('social_honeypot_icwsm_2011/legitimate_users_tweets.txt', \n",
    "                              sep='\\t', \n",
    "                              header=None,\n",
    "                              names=[\"UserID\", \"TweetID\", \"Tweet\", \"CreatedAt\"])\n",
    "\n",
    "df_bots_tweets['is_bot'] = 1\n",
    "df_humans_tweets['is_bot'] = 0\n",
    "\n",
    "df_combined = pd.concat([df_bots_tweets, df_humans_tweets], axis=0, ignore_index=True)\n",
    "\n",
    "df_combined = df_combined.dropna(subset=['Tweet'])\n",
    "df_combined['Tweet'] = df_combined['Tweet'].astype(str)\n",
    "df_combined = df_combined[df_combined['Tweet'].str.strip() != '']\n",
    "\n",
    "# First, create train/test split while preserving user groups\n",
    "group_split = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_combined['Tweet']\n",
    "y = df_combined['is_bot']\n",
    "groups = df_combined['UserID']\n",
    "\n",
    "# Get train/test indices\n",
    "train_idx, test_idx = next(group_split.split(X, y, groups=groups))\n",
    "\n",
    "X_train = X.iloc[train_idx]\n",
    "X_test = X.iloc[test_idx]\n",
    "y_train = y.iloc[train_idx]\n",
    "y_test = y.iloc[test_idx]\n",
    "groups_train = groups.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4473428 tweets\n",
      "Test set size: 1106627 tweets\n",
      "Unique users in training: 31882\n",
      "Unique users in test: 7971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set size: {len(X_train)} tweets\")\n",
    "print(f\"Test set size: {len(X_test)} tweets\")\n",
    "print(f\"Unique users in training: {len(groups_train.unique())}\")\n",
    "print(f\"Unique users in test: {len(groups.iloc[test_idx].unique())}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        max_features=1000,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english',\n",
    "        strip_accents='unicode',\n",
    "        min_df=2  # Ignore terms that appear in less than 2 documents\n",
    "    )),\n",
    "    ('classifier', LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        max_iter=200  # Increase max iterations for convergence\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Cross-validation on training data\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "fold_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82    518998\n",
      "           1       0.74      0.77      0.75    375688\n",
      "\n",
      "    accuracy                           0.79    894686\n",
      "   macro avg       0.78      0.79      0.79    894686\n",
      "weighted avg       0.79      0.79      0.79    894686\n",
      "\n",
      "\n",
      "Fold 2 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81    523577\n",
      "           1       0.73      0.76      0.75    371109\n",
      "\n",
      "    accuracy                           0.79    894686\n",
      "   macro avg       0.78      0.78      0.78    894686\n",
      "weighted avg       0.79      0.79      0.79    894686\n",
      "\n",
      "\n",
      "Fold 3 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80    519098\n",
      "           1       0.72      0.77      0.74    375588\n",
      "\n",
      "    accuracy                           0.78    894686\n",
      "   macro avg       0.77      0.78      0.77    894686\n",
      "weighted avg       0.78      0.78      0.78    894686\n",
      "\n",
      "\n",
      "Fold 4 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81    514687\n",
      "           1       0.74      0.77      0.75    379998\n",
      "\n",
      "    accuracy                           0.79    894685\n",
      "   macro avg       0.78      0.78      0.78    894685\n",
      "weighted avg       0.79      0.79      0.79    894685\n",
      "\n",
      "\n",
      "Fold 5 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80    519849\n",
      "           1       0.72      0.76      0.74    374836\n",
      "\n",
      "    accuracy                           0.78    894685\n",
      "   macro avg       0.77      0.77      0.77    894685\n",
      "weighted avg       0.78      0.78      0.78    894685\n",
      "\n",
      "\n",
      "Average CV accuracy: 0.783 (±0.005)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Final Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81    650165\n",
      "           1       0.73      0.75      0.74    456462\n",
      "\n",
      "    accuracy                           0.78   1106627\n",
      "   macro avg       0.78      0.78      0.78   1106627\n",
      "weighted avg       0.78      0.78      0.78   1106627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (cv_train_idx, cv_val_idx) in enumerate(group_kfold.split(X_train, y_train, groups=groups_train), 1):\n",
    "    # Get fold data\n",
    "    X_fold_train = X_train.iloc[cv_train_idx]\n",
    "    y_fold_train = y_train.iloc[cv_train_idx]\n",
    "    X_fold_val = X_train.iloc[cv_val_idx]\n",
    "    y_fold_val = y_train.iloc[cv_val_idx]\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = pipeline.predict(X_fold_val)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f\"\\nFold {fold} Results:\")\n",
    "    print(classification_report(y_fold_val, predictions))\n",
    "    \n",
    "    # Store fold score\n",
    "    fold_scores.append(pipeline.score(X_fold_val, y_fold_val))\n",
    "\n",
    "print(f\"\\nAverage CV accuracy: {np.mean(fold_scores):.3f} (±{np.std(fold_scores):.3f})\")\n",
    "\n",
    "print(\"\\nTraining final model on all training data...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nFinal Test Set Performance:\")\n",
    "test_predictions = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example predictions:\n"
     ]
    }
   ],
   "source": [
    "def predict_tweet(tweet_text, trained_pipeline):\n",
    "    \"\"\"\n",
    "    Predict whether a tweet is from a bot or human.\n",
    "    \n",
    "    Args:\n",
    "        tweet_text (str): The text of the tweet to classify\n",
    "        trained_pipeline: Trained sklearn pipeline\n",
    "    \n",
    "    Returns:\n",
    "        int: 1 for bot, 0 for human\n",
    "    \"\"\"\n",
    "    return trained_pipeline.predict([tweet_text])[0]\n",
    "\n",
    "# Example predictions\n",
    "print(\"\\nExample predictions:\")\n",
    "example_tweets = [\n",
    "    \"Click here to win a free iPhone! Limited time offer!\",\n",
    "    \"Just had a great coffee with friends at the local cafe.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tweet: Click here to win a free iPhone! Limited time offer!\n",
      "Prediction: Bot\n",
      "\n",
      "Tweet: Just had a great coffee with friends at the local cafe.\n",
      "Prediction: Bot\n"
     ]
    }
   ],
   "source": [
    "for tweet in example_tweets:\n",
    "    prediction = predict_tweet(tweet, pipeline)\n",
    "    print(f\"\\nTweet: {tweet}\")\n",
    "    print(f\"Prediction: {'Bot' if prediction == 1 else 'Human'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bot_classifier.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, 'bot_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: I actually liked that Keanu Reeves voiced Shadow in new sonic movie!\n",
      "Prediction: Human\n",
      "\n",
      "Tweet: Had lunch with friends\n",
      "Prediction: Human\n",
      "\n",
      "Tweet: Free Palestine!\n",
      "Prediction: Bot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load('bot_classifier.joblib')\n",
    "\n",
    "tweets = [\"I actually liked that Keanu Reeves voiced Shadow in new sonic movie!\", \"Had lunch with friends\", \"Free Palestine!\"]\n",
    "predictions = loaded_model.predict(tweets)\n",
    "for tweet, pred in zip(tweets, predictions):\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    print(f\"Prediction: {'Bot' if pred == 1 else 'Human'}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
